{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRYING TO LOCATE THE FACE DIRECTLY IN 1 STEP\n",
    "ALL RELEVANT FILES ARE IN HAAR_TRAIN_1STEP\n",
    "\n",
    "Cascade face detection:\n",
    "1) Label images\n",
    "    1a) label the head\n",
    "    1b) label non-head areas\n",
    "2) Train the classifier\n",
    "    2a) prepare negative samples\n",
    "    2b) prepare positive samples\n",
    "    2c) cascade training\n",
    "3) Test the classifier\n",
    "    what is a good image size, min_neighbor value, minhitrate, etc.\n",
    "    \n",
    "useful links:\n",
    "\n",
    "http://docs.opencv.org/2.4/doc/user_guide/ug_traincascade.html#cascade-training\n",
    "http://docs.opencv.org/2.4/modules/objdetect/doc/cascade_classification.html?highlight=detectmultiscale\n",
    "http://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_Image_Object_Detection_Face_Detection_Haar_Cascade_Classifiers.php\n",
    "https://sites.google.com/site/5kk73gpu2012/assignment/viola-jones-face-detection#TOC-Image-Pyramid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label whale heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_3766.jpg\n",
      "w_7631.jpg\n",
      "w_5921.jpg\n",
      "w_5072.jpg\n",
      "w_6899.jpg\n",
      "w_2049.jpg\n",
      "w_9959.jpg\n",
      "w_7938.jpg\n",
      "w_3572.jpg\n",
      "w_746.jpg\n",
      "w_2381.jpg\n",
      "w_4762.jpg\n",
      "w_9489.jpg\n",
      "w_882.jpg\n",
      "w_8511.jpg\n",
      "w_5857.jpg\n",
      "w_7884.jpg\n",
      "w_5962.jpg\n",
      "w_2892.jpg\n",
      "w_8383.jpg\n",
      "w_8412.jpg\n",
      "w_10878.jpg\n",
      "w_9931.jpg\n",
      "w_5104.jpg\n",
      "w_5288.jpg\n",
      "w_8966.jpg\n",
      "w_8640.jpg\n",
      "w_1723.jpg\n",
      "w_3533.jpg\n",
      "w_2614.jpg\n",
      "w_5367.jpg\n",
      "w_9219.jpg\n",
      "w_1012.jpg\n",
      "w_8100.jpg\n",
      "w_1884.jpg\n",
      "w_4310.jpg\n",
      "w_7109.jpg\n",
      "w_4752.jpg\n",
      "w_107.jpg\n",
      "w_7562.jpg\n",
      "w_4697.jpg\n",
      "w_1816.jpg\n",
      "w_5650.jpg\n",
      "w_10860.jpg\n",
      "w_3258.jpg\n",
      "w_432.jpg\n",
      "w_11239.jpg\n",
      "w_8662.jpg\n",
      "w_1978.jpg\n",
      "w_4403.jpg\n",
      "w_2037.jpg\n",
      "w_3829.jpg\n",
      "w_11337.jpg\n",
      "w_6118.jpg\n",
      "w_4978.jpg\n",
      "w_5200.jpg\n",
      "w_40.jpg\n",
      "w_6176.jpg\n",
      "w_11142.jpg\n",
      "w_6574.jpg\n",
      "w_10978.jpg\n",
      "w_6398.jpg\n",
      "w_10925.jpg\n",
      "w_6152.jpg\n",
      "w_6332.jpg\n",
      "w_9617.jpg\n",
      "w_10575.jpg\n",
      "w_1689.jpg\n",
      "w_7500.jpg\n",
      "w_10116.jpg\n",
      "w_3923.jpg\n",
      "w_1481.jpg\n",
      "w_11356.jpg\n",
      "w_2472.jpg\n",
      "w_7744.jpg\n",
      "w_11366.jpg\n",
      "w_10875.jpg\n",
      "w_6807.jpg\n",
      "w_3512.jpg\n",
      "w_1075.jpg\n",
      "w_1048.jpg\n",
      "w_7019.jpg\n",
      "w_6984.jpg\n",
      "w_5437.jpg\n",
      "w_6482.jpg\n",
      "w_7262.jpg\n",
      "w_9950.jpg\n",
      "w_6081.jpg\n",
      "w_6192.jpg\n",
      "w_10346.jpg\n",
      "w_8106.jpg\n",
      "w_3688.jpg\n",
      "w_7926.jpg\n",
      "w_11248.jpg\n",
      "w_10538.jpg\n",
      "w_6167.jpg\n",
      "w_3554.jpg\n",
      "w_5966.jpg\n",
      "w_492.jpg\n",
      "w_4050.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import choice\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pylab as pl\n",
    "\n",
    "files = []\n",
    "\n",
    "for file in os.listdir(\"../imgs\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        files.append(file[:-4])\n",
    "\n",
    "# number of images to select\n",
    "n = 100\n",
    "\n",
    "# select one file, check whether it's already in clicks, detect the nose and the blowhole,\n",
    "# cut the face out, then save the clicks\n",
    "i = 0\n",
    "while i < n:  \n",
    "    file_to_analyze = choice(files)\n",
    "    # check whether this file is already in clicks\n",
    "    already_analized_files = []\n",
    "    for file in os.listdir(\"../haar_train_1step/clicks_head\"):\n",
    "        if file.endswith(\".save\"):\n",
    "            already_analized_files.append(file[:-5])\n",
    "    # stupidity check\n",
    "    if len(already_analized_files) == len(files):\n",
    "        # all files have been analyzed.\n",
    "        break\n",
    "    # if file is not in directory already, mark the nose and blowhole    \n",
    "    if (file_to_analyze not in already_analized_files):\n",
    "        print file_to_analyze+'.jpg'\n",
    "        im = np.array(Image.open('../imgs/'+file_to_analyze+'.jpg'))\n",
    "        \n",
    "        pl.figure(figsize = (15,9))  \n",
    "        pl.imshow(im,aspect='equal')\n",
    "        # coarse selection of the head - first select two points to mark a rectangle around the head \n",
    "        # be generous and don't mark points too close to the whale's face\n",
    "        rect = pl.ginput(2,timeout=0)\n",
    "        pl.close()\n",
    "        \n",
    "        # the rectangle is cut \n",
    "        if rect[0][0] != rect[1][0] or rect[0][1] != rect[1][1]:\n",
    "            # the x coordinate is the second coordinate [1] on display\n",
    "            xmin = np.min([rect[0][1],rect[1][1]])\n",
    "            xmax = np.max([rect[0][1],rect[1][1]])\n",
    "            ymin = np.min([rect[0][0],rect[1][0]])\n",
    "            ymax = np.max([rect[0][0],rect[1][0]])\n",
    "        else:\n",
    "            print 'rectangle was not cut out properly'\n",
    "            raise ValueError\n",
    "             \n",
    "        im_cut = im[xmin:xmax,ymin:ymax]\n",
    "\n",
    "        # display the magnified rectangle to mark the exact location of the nose and the blowhole\n",
    "        pl.figure(figsize = (15,9))\n",
    "        pl.imshow(im_cut,aspect='equal',interpolation='nearest')\n",
    "        # step 1: mark the top of the nose\n",
    "        # step 2: mark the middle of the blowhole\n",
    "        head = pl.ginput(2,timeout=0)\n",
    "        \n",
    "        pl.close()\n",
    "        \n",
    "        # dump clicks\n",
    "        f = open('../haar_train_1step/clicks_head/'+file_to_analyze+'.save','w')\n",
    "        pickle.dump([file_to_analyze,rect,head],f)\n",
    "        f.close()\n",
    "        \n",
    "        i = i + 1   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label negative areas, areas that do not contain a whale's head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_6899\n",
      "w_5288\n",
      "w_9931\n",
      "w_7262\n",
      "w_5921\n",
      "w_1816\n",
      "w_6152\n",
      "w_1481\n",
      "w_7019\n",
      "w_4697\n",
      "w_11366\n",
      "w_3554\n",
      "w_8412\n",
      "w_8640\n",
      "w_2381\n",
      "w_1689\n",
      "w_10978\n",
      "w_4050\n",
      "w_10878\n",
      "w_4762\n",
      "w_1048\n",
      "w_10875\n",
      "w_6332\n",
      "w_1884\n",
      "w_5200\n",
      "w_10575\n",
      "w_10860\n",
      "w_7926\n",
      "w_5437\n",
      "w_6574\n",
      "w_4752\n",
      "w_1978\n",
      "w_3258\n",
      "w_4978\n",
      "w_9950\n",
      "w_9617\n",
      "w_40\n",
      "w_7631\n",
      "w_9959\n",
      "w_11248\n",
      "w_6192\n",
      "w_3533\n",
      "w_7938\n",
      "w_8966\n",
      "w_7500\n",
      "w_2037\n",
      "w_7744\n",
      "w_5650\n",
      "w_5367\n",
      "w_11239\n",
      "w_746\n",
      "w_1723\n",
      "w_1012\n",
      "w_5966\n",
      "w_5962\n",
      "w_7109\n",
      "w_10925\n",
      "w_6118\n",
      "w_8383\n",
      "w_107\n",
      "w_2049\n",
      "w_8662\n",
      "w_432\n",
      "w_2892\n",
      "w_5072\n",
      "w_8511\n",
      "w_7562\n",
      "w_6482\n",
      "w_4310\n",
      "w_6398\n",
      "w_7884\n",
      "w_4403\n",
      "w_11337\n",
      "w_11142\n",
      "w_2614\n",
      "w_9489\n",
      "w_11356\n",
      "w_5104\n",
      "w_9219\n",
      "w_6081\n",
      "w_3829\n",
      "w_10538\n",
      "w_882\n",
      "w_1075\n",
      "w_6176\n",
      "w_3512\n",
      "w_6984\n",
      "w_3572\n",
      "w_10116\n",
      "w_10346\n",
      "w_8106\n",
      "w_8100\n",
      "w_6807\n",
      "w_492\n",
      "w_5857\n",
      "w_3923\n",
      "w_6167\n",
      "w_3688\n",
      "w_2472\n",
      "w_3766\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from random import choice\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pylab as pl\n",
    "\n",
    "files = []\n",
    "\n",
    "# images with heads already labeled\n",
    "for file in os.listdir(\"../haar_train_1step/clicks_head\"):\n",
    "    if file.endswith(\".save\"):\n",
    "        files.append(file[:-5])\n",
    "\n",
    "# check which of these files were analized already\n",
    "already_analized_files = []\n",
    "for file in os.listdir(\"../haar_train_1step/clicks_other\"):\n",
    "    if file.endswith(\".save\"):\n",
    "        already_analized_files.append(file[:-5])\n",
    "\n",
    "# click on the rest\n",
    "files_to_analyze = list(set(files) - set(already_analized_files))\n",
    "\n",
    "for i in files_to_analyze: \n",
    "    print i\n",
    "    im = np.array(Image.open('../imgs/'+i+'.jpg'))\n",
    "\n",
    "    pl.figure(figsize = (14,8))  \n",
    "    pl.imshow(im,aspect='equal')\n",
    "    # select a rectangle without a face\n",
    "    rect = pl.ginput(2,timeout=0)\n",
    "    pl.close()\n",
    "\n",
    "    # dump clicks\n",
    "    f = open('../haar_train_1step/clicks_other/'+i+'.save','w')\n",
    "    pickle.dump([i,rect],f)\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare negative images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# delete all images in directory\n",
    "files = glob.glob('../haar_train_1step/negative_sample/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "non_whale_faces = []\n",
    "for file in os.listdir(\"../haar_train_1step/clicks_other\"):\n",
    "    if file.endswith(\".save\"):\n",
    "        non_whale_faces.append(file[:-5])\n",
    "\n",
    "# calculate average mean and std of images\n",
    "#mean = 0e0\n",
    "#std = 0e0\n",
    "#for i in non_whale_faces:\n",
    "#    im = np.array(Image.open('../imgs/'+file_to_analyze+'.jpg').convert('L'))\n",
    "#    mean = mean + np.mean(im)\n",
    "#    std = std + np.std(im)\n",
    "#mean = mean / float(len(non_whale_faces))\n",
    "#std = std / float(len(non_whale_faces))\n",
    "#print mean, std\n",
    "\n",
    "mean = 111.031397463 \n",
    "std = 18.4898562094\n",
    "\n",
    "\n",
    "for i in non_whale_faces:\n",
    "    # pickle load\n",
    "    f = open('../haar_train_1step/clicks_other/'+i+'.save','r')\n",
    "    [file_to_analyze,rect] = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    # open image\n",
    "    im = np.array(Image.open('../imgs/'+file_to_analyze+'.jpg').convert('L'))\n",
    "    \n",
    "    # cut out the rectangle\n",
    "    if rect[0][0] != rect[1][0] or rect[0][1] != rect[1][1]:\n",
    "        # the x coordinate is the second coordinate [1] on display\n",
    "        xmin = np.min([rect[0][1],rect[1][1]])\n",
    "        xmax = np.max([rect[0][1],rect[1][1]])\n",
    "        ymin = np.min([rect[0][0],rect[1][0]])\n",
    "        ymax = np.max([rect[0][0],rect[1][0]])\n",
    "    else:\n",
    "        print 'rectangle was not cut out properly'\n",
    "        raise ValueError\n",
    "    \n",
    "    im_cut = im[xmin:xmax,ymin:ymax]\n",
    "    \n",
    "    # standardize the background pics using whole pic values\n",
    "    im_cut = (im_cut - np.mean(im_cut)) / np.std(im_cut)\n",
    "    # restandardize based on the average means and stds\n",
    "    im_cut = (im_cut*std)+mean\n",
    "    im_cut[im_cut < 0e0] = 0e0\n",
    "    im_cut[im_cut > 255e0] = 255e0\n",
    "    \n",
    "    imsave('../haar_train_1step/negative_sample/'+i+'_0.jpg', im_cut)\n",
    "    # rotate images\n",
    "    imsave('../haar_train_1step/negative_sample/'+i+'_1.jpg', np.rot90(im_cut,k=1))\n",
    "    imsave('../haar_train_1step/negative_sample/'+i+'_2.jpg', np.rot90(im_cut,k=2))\n",
    "    imsave('../haar_train_1step/negative_sample/'+i+'_3.jpg', np.rot90(im_cut,k=3))\n",
    "\n",
    "# create the description file of negative samples\n",
    "# these files are in ../haar_train/negative_sample\n",
    "non_whale_faces = []\n",
    "for file in os.listdir(\"../haar_train_1step/negative_sample\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        non_whale_faces.append(file)\n",
    "f = open('../haar_train_1step/bg.txt','w')\n",
    "for i in non_whale_faces:\n",
    "    f.write('../haar_train_1step/negative_sample/'+i+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare positive images, step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:57: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "from scipy.misc import imresize\n",
    "from scipy.misc import imsave\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "## parameters for the whale face images:\n",
    "# edge width in unit of nose-blowhole distance\n",
    "edge = 0.4\n",
    "# color or grayscale image\n",
    "color = True\n",
    "\n",
    "# delete all images in directory\n",
    "files = glob.glob('../haar_train_1step/clicked_whale_faces/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "whale_faces = []\n",
    "for file in os.listdir(\"../haar_train_1step/clicks_head\"):\n",
    "    if file.endswith(\".save\"):\n",
    "        whale_faces.append(file[:-5])\n",
    "\n",
    "for i in whale_faces:\n",
    "    # pickle load\n",
    "    f = open('../haar_train_1step/clicks_head/'+i+'.save','r')\n",
    "    [file_to_analyze,rect,head] = pickle.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    # open image\n",
    "    im = np.array(Image.open('../imgs/'+i+'.jpg'))\n",
    "    \n",
    "    # cut out the rectangle\n",
    "    if rect[0][0] != rect[1][0] or rect[0][1] != rect[1][1]:\n",
    "        # the x coordinate is the second coordinate [1] on display\n",
    "        xmin = np.min([rect[0][1],rect[1][1]])\n",
    "        xmax = np.max([rect[0][1],rect[1][1]])\n",
    "        ymin = np.min([rect[0][0],rect[1][0]])\n",
    "        ymax = np.max([rect[0][0],rect[1][0]])\n",
    "    else:\n",
    "        print 'rectangle was not cut out properly'\n",
    "        raise ValueError\n",
    "    \n",
    "    # head clicks in im coordinates\n",
    "    headc = np.zeros([2,2])\n",
    "    headc[0,1] = head[0][1] + xmin\n",
    "    headc[1,1] = head[1][1] + xmin\n",
    "    headc[0,0] = head[0][0] + ymin\n",
    "    headc[1,0] = head[1][0] + ymin\n",
    "    \n",
    "    # rotate the image such that the nose-blowhole line is vertical, nose is up\n",
    "    dx = headc[0,1] - headc[1,1]\n",
    "    dy = headc[0,0] - headc[1,0]\n",
    "    theta = np.arctan2(dx,dy) + np.pi/2e0 # added 90 deg to rotate the nose up\n",
    "    if dx/dy >= 0:\n",
    "        theta = theta + 2e0*np.pi # range is between 0 and 2pi now\n",
    "    im_rotate = rotate(im,np.degrees(theta),mode='nearest')\n",
    "\n",
    "    # rotate the head and blowhole coordinates\n",
    "    # the center of im_cut\n",
    "    xc_cut = np.shape(im)[0]/2e0 + 0.5\n",
    "    yc_cut = np.shape(im)[1]/2e0 + 0.5\n",
    "    # the center of im_rotate\n",
    "    xc_rot = np.shape(im_rotate)[0]/2e0 + 0.5\n",
    "    yc_rot = np.shape(im_rotate)[1]/2e0 + 0.5\n",
    "    # rotate   \n",
    "    nose = np.zeros(2)\n",
    "    nose[1] = (headc[0,1]-xc_cut)*np.cos(theta) - (headc[0,0]-yc_cut)*np.sin(theta) + xc_rot\n",
    "    nose[0] = (headc[0,1]-xc_cut)*np.sin(theta) + (headc[0,0]-yc_cut)*np.cos(theta) + yc_rot\n",
    "    blowhole = np.zeros(2)\n",
    "    blowhole[1] = (headc[1,1]-xc_cut)*np.cos(theta) - (headc[1,0]-yc_cut)*np.sin(theta) + xc_rot\n",
    "    blowhole[0] = (headc[1,1]-xc_cut)*np.sin(theta) + (headc[1,0]-yc_cut)*np.cos(theta) + yc_rot\n",
    "\n",
    "    # cut a square piece out and add edge*distance edge around the selected region\n",
    "    distance = np.sqrt((nose[0]-blowhole[0])**2e0 + (nose[1]-blowhole[1])**2e0)\n",
    "    im_save = im_rotate[nose[1]-distance*edge:blowhole[1]+distance*edge,nose[0]-distance*(0.5+edge):nose[0]+distance*(0.5+edge)]\n",
    "        \n",
    "    # save\n",
    "    if color:\n",
    "        imsave('../haar_train_1step/clicked_whale_faces/'+i+'.jpg', im_save)\n",
    "    else:\n",
    "        im_grayscale = np.average(imresize(im_save,[im_size,im_size]),axis=2, weights=[0.299, 0.587, 0.144])\n",
    "        imsave('../haar_train_1step/clicked_whale_faces/'+i+'.jpg', im_grayscale)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare positive images, step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import numpy as np\n",
    "from random import choice\n",
    "from scipy.misc import imsave\n",
    "\n",
    "# based on previous cell\n",
    "mean = 111.031397463 \n",
    "std = 18.4898562094\n",
    "\n",
    "# number of random angles for rotation\n",
    "n = 10\n",
    "\n",
    "whale_faces = []\n",
    "for file in os.listdir(\"../haar_train_1step/clicked_whale_faces\"):\n",
    "    if file.endswith(\".jpg\"):\n",
    "        whale_faces.append(file)\n",
    "\n",
    "# delete all images in directory\n",
    "files = glob.glob('../haar_train_1step/positive_sample_normalized_straight/*')\n",
    "for f in files:\n",
    "    os.remove(f)        \n",
    "\n",
    "f = open('../haar_train_1step/annotations_normalized_straight.lst','w')\n",
    "ii = 0\n",
    "for j in range(n):\n",
    "    for i in whale_faces:\n",
    "        # open file\n",
    "        face = np.array(Image.open('../haar_train_1step/clicked_whale_faces/'+i).convert('L'))\n",
    "        \n",
    "        # rotate with a random angle and cut the central part out\n",
    "        angle = np.random.uniform(-5,5)        \n",
    "        face_rot = rotate(face,angle)\n",
    "        (x,y) = np.shape(face)\n",
    "        x = int(x/np.sqrt(2e0))\n",
    "        (x_rot,y_rot) = np.shape(face_rot)\n",
    "        face_rotate = np.zeros([x,x])\n",
    "        face_rotate = face_rot[x_rot/2e0 - x/2e0:x_rot/2e0 + x/2e0,x_rot/2e0 - x/4e0:x_rot/2e0 + x/4e0]        \n",
    "        \n",
    "        # standardize the face using the whole image values\n",
    "        face_rotate = (face_rotate - np.mean(face_rotate)) / np.std(face_rotate)\n",
    "        # restandardize based on the average means and stds\n",
    "        face_rotate = (face_rotate*std)+mean\n",
    "        face_rotate[face_rotate < 0e0] = 0e0\n",
    "        face_rotate[face_rotate > 255e0] = 255e0\n",
    "        \n",
    "        # save image\n",
    "        imsave('../haar_train_1step/positive_sample_normalized_straight/'+str(ii)+'.jpg', face_rotate)\n",
    "        # write annotations.lst\n",
    "        f.write('positive_sample_normalized_straight/'+str(ii)+'.jpg 1 0 0 '+str(x)+' '+str(x)+'\\n')\n",
    "        \n",
    "        ii = ii + 1\n",
    "f.close()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run opencv: create vec file, and train the cascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info file name: ../haar_train_1step/annotations_normalized_straight.lst\n",
      "Img file name: (NULL)\n",
      "Vec file name: ../haar_train_1step/whale_face_80_normalized_straight.vec\n",
      "BG  file name: (NULL)\n",
      "Num: 10000\n",
      "BG color: 0\n",
      "BG threshold: 80\n",
      "Invert: FALSE\n",
      "Max intensity deviation: 40\n",
      "Max x angle: 1.1\n",
      "Max y angle: 1.1\n",
      "Max z angle: 0.5\n",
      "Show samples: FALSE\n",
      "Width: 40\n",
      "Height: 80\n",
      "Create training samples from images collection...\n",
      "Done. Created 10000 samples\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# size of positive images\n",
    "size = 80\n",
    "\n",
    "\n",
    "# create vec file from annotated files\n",
    "out = subprocess.check_output([\"opencv_createsamples\",\"-vec\", \"../haar_train_1step/whale_face_\"+str(size)+\"_normalized_straight.vec\", \"-info\", \n",
    "                               \"../haar_train_1step/annotations_normalized_straight.lst\",\"-num\", \"10000\", \"-w\", str(size/2), \"-h\", str(size)])\n",
    "\n",
    "print out\n",
    "\n",
    "# an example command line to copy into a terminal\n",
    "# opencv_traincascade -data ../haar_train/cascade -vec ../haar_train/whale_face.vec -bg ../haar_train/bg.txt \n",
    "# -numStages 20 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 5000 -numNeg 800 -w 24 -h 24 -mode ALL \n",
    "# -precalcValBufSize 1024 -precalcIdxBufSize 1024\n",
    "# see http://stackoverflow.com/questions/10863560/haar-training-opencv-assertion-failed why numPos is not 5000\n",
    "#with open('test.log', 'w') as f:\n",
    "#    process = subprocess.Popen([\"opencv_traincascade\",\"-data\", \"../haar_train/cascade\", \"-vec\", \"../haar_train/whale_face.vec\",\n",
    "#                               \"-bg\", \"../haar_train/bg.txt\", \"-numStages\", \"20\", \"-minHitRate\", \"0.999\", \"-maxFalseAlarmRate\",\n",
    "#                               \"0.5\", \"-numPos\", \"4850\",\"-numNeg\", \"800\", \"-w\", str(size), \"-h\", str(size), \"-mode\", \"ALL\", \n",
    "#                               \"-precalcValBufSize\", \"1024\",\"-precalcIdxBufSize\", \"1024\"], stdout=subprocess.PIPE)\n",
    "#    for c in iter(lambda: process.stdout.read(1), ''):\n",
    "#        sys.stdout.write(c)\n",
    "#        f.write(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters I change when creating the cascade files:\n",
    "    - width and height of positive images\n",
    "    - numStages in opencv_traincascade\n",
    "    - minhitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "totalPositiveSamples = 10000\n",
    "Im_size = [40,60,80]\n",
    "NumCascadeStages = [25,30]\n",
    "MinHitRate = [0.99, 0.995, 0.999]\n",
    "\n",
    "for i in Im_size:\n",
    "    for j in NumCascadeStages:\n",
    "        for k in MinHitRate:\n",
    "            num = np.int(totalPositiveSamples / (1 + (j - 1) * (1 - k))*0.95)\n",
    "            #print 'opencv_traincascade -data ../haar_train_1step/cascade_'+str(i)+'_'+str(j)+'_'+str(k)+' -vec ../haar_train_1step/whale_face_'+str(i)+'.vec -bg ../haar_train_1step/bg.txt -numStages '+str(j)+' -minHitRate '+str(k)+' -maxFalseAlarmRate 0.5 -numPos '+str(num)+' -numNeg 2000 -w '+str(i)+' -h '+str(i)+' -mode ALL -precalcValBufSize 1024 -precalcIdxBufSize 1024'\n",
    "            subprocess.Popen('nohup opencv_traincascade -data cascade_'+str(i)+'_'+str(j)+'_'+str(k)+'_normalized_straight -vec whale_face_'+str(i)+'_normalized_straight.vec -bg bg.txt -numStages '+str(j)+' -minHitRate '+str(k)+' -maxFalseAlarmRate 0.5 -numPos '+str(num)+' -numNeg 4000 -w '+str(i/2)+' -h '+str(i)+' -featureType LBP -precalcValBufSize 5000 -precalcIdxBufSize 5000 > out_'+str(i)+'_'+str(j)+'_'+str(k)+'_normalized_straight.txt &', shell=True)\n",
    "            subprocess.Popen('mkdir cascade_'+str(i)+'_'+str(j)+'_'+str(k)+'_normalized_straight', shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluate the cascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.   10.   20.   30.   40.   50.   60.   70.   80.   90.  100.  110.\n",
      "  120.  130.  140.  150.  160.  170.  180.  190.  200.  210.  220.  230.\n",
      "  240.  250.  260.  270.  280.  290.  300.  310.  320.  330.  340.  350.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b76414cffbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mscalefac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import glob\n",
    "from scipy.misc import imresize\n",
    "\n",
    "# based on previous code\n",
    "mean = 111.031397463 \n",
    "std = 18.4898562094\n",
    "\n",
    "Im_size = [40,60,80]\n",
    "NumCascadeStages = [25, 30]\n",
    "MinHitRate = [0.99,0.995,0.999]\n",
    "\n",
    "# delete all images in test directory\n",
    "files = glob.glob('../haar_train_1step/test/*')\n",
    "for f in files:\n",
    "    os.remove(f)\n",
    "\n",
    "files = []\n",
    "for file in os.listdir(\"../imgs/\"):\n",
    "    if file.endswith('.jpg'):\n",
    "        files.append(file[:-4])\n",
    "\n",
    "# number of images to map \n",
    "n = 100\n",
    "\n",
    "if n > len(files):\n",
    "    n = len(files)\n",
    "\n",
    "min_neighbors = np.arange(1,10,step = 1)\n",
    "min_neighbors = np.append(min_neighbors,10e0**np.linspace(1e0,2e0,21e0))\n",
    "rot = np.linspace(0,350,36)\n",
    "\n",
    "scalefac = 1.01\n",
    "\n",
    "for ii in range(n):\n",
    "    f = np.random.choice(files)\n",
    "    files.remove(f)\n",
    "        \n",
    "    if ii%10 == 0:\n",
    "        print ii,' images done.'\n",
    "\n",
    "    # open image\n",
    "    im = np.array(Image.open('../imgs/'+f+'.jpg'))\n",
    "\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray = (gray - np.mean(gray)) / np.std(gray)\n",
    "    # restandardize based on the average means and stds\n",
    "    gray = (gray*std)+mean\n",
    "    gray[gray < 0e0] = 0e0\n",
    "    gray[gray > 255e0] = 255e0\n",
    "    gray_ori = np.array(gray, dtype='uint8')\n",
    "    \n",
    "    # rotate image to find the head\n",
    "    kk = 0\n",
    "    found = np.zeros(len(rot))\n",
    "    \n",
    "    print f\n",
    "    \n",
    "    for i in Im_size:\n",
    "        for j in NumCascadeStages:\n",
    "            for k in MinHitRate:\n",
    "                found_old = 0\n",
    "                for jj in np.arange(len(rot)):\n",
    "                    gray = rotate(gray_ori,rot[jj])\n",
    "\n",
    "                    a = np.min(np.shape(gray))\n",
    "\n",
    "                    face_cascade = cv2.CascadeClassifier('../haar_train_1step/cascade_'+str(i)+'_'+str(j)+'_'+str(k)+'_normalized_straight/cascade.xml')\n",
    "                    \n",
    "                    found = 0\n",
    "                    \n",
    "                    faces_all = []\n",
    "                    \n",
    "                    for l in np.arange(len(min_neighbors)):\n",
    "                        faces = face_cascade.detectMultiScale(gray, scaleFactor=scalefac, minNeighbors = int(min_neighbors[l]), minSize=(a/20, a/20))\n",
    "                        if np.shape(faces)[0] == 1:\n",
    "                            found = found + 1\n",
    "                            faces_all.append(faces)\n",
    "                    if found > found_old:\n",
    "                        face_cut = faces_all[0]\n",
    "\n",
    "                        gray_copy = np.copy(gray)\n",
    "                        for (x,y,w,h) in face_cut:\n",
    "                            cv2.rectangle(gray_copy,(x,y),(x+w,y+h),(255,255,255),10)\n",
    "                            imsave('../haar_train_1step/test2/'+f+'_'+str(i)+'_'+str(j)+'_'+str(k)+'_'+str(jj)+'.jpg', imresize(gray_copy,[np.shape(gray)[0]/4,np.shape(gray)[1]/4]))\n",
    "                            #im_rot = rotate(im,rot[jj])\n",
    "                            #imsave('../haar_train_1step/test2/head_'+f+'_'+str(i)+'_'+str(j)+'_'+str(k)+'_'+str(jj)+'.jpg', im_rot[y:y+h,x:x+w])\n",
    "                    found_old = np.max([found,found_old])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the score of different cascades\n",
    "\n",
    "gradients around the central grid point:\n",
    "\n",
    "60_20_0.99:  1 - 38/104 = 63%\n",
    "60_20_0.995: 1 - 33/104 = 68%\n",
    "60_20_0.999: 1 - 53/104 = 49%\n",
    "\n",
    "60_15_0.995: 1 - 84/104 = 19%\n",
    "60_20_0.995: 1 - 33/104 = 68%\n",
    "60_25_0.995: 1 - 25/104 = 76%\n",
    "\n",
    "40_20_0.995: 1 - 34/108 = 68%\n",
    "60_20_0.995: 1 - 33/104 = 68%\n",
    "80_20_0.995: 1 - 41/95 = 57%\n",
    "\n",
    "prediction: 40_25_0.995 should also have a similarly high score to 60_25_0.995 but it is faster to run.\n",
    "40_25_0.995: 1 - 27/105 = 74%\n",
    "\n",
    "gradients centered around 60_25_0.995:\n",
    "\n",
    "60_25_0.99:  1 - 25/104 = 76%\n",
    "60_25_0.995: 1 - 25/104 = 76%\n",
    "60_25_0.999: 1 - 25/104 = 76%\n",
    "\n",
    "40_25_0.995: 1 - 27/105 = 74%\n",
    "60_25_0.995: 1 - 25/104 = 76%\n",
    "80_25_0.995: 1 - 23/93 = 75%\n",
    "\n",
    "other checks to be on the safe side:\n",
    "40_25_0.99: 1 - 30/106 = 72%\n",
    "\n",
    "started runs of 60_30_0.995 and 60_35_0.995.\n",
    "\n",
    "in the current vec files, 10 random rotation angles are used. I also check how the score changes if i use 20, 30, 40 angles instead (larger vec file).\n",
    "\n",
    "I also studied other cascade parameters: number of rotation angle, scale factor, and number of min_neighbor values\n",
    "the study is on 10 images only so the accuracy isn't good. but i still learnt from it and improved the score.\n",
    "\n",
    "40 25 0.99\n",
    "    20 deg rot angle\n",
    "    1.05 scale factor\n",
    "    31 min_neighbor values\n",
    "        7 out of 10 images successfully identified\n",
    "        \n",
    "    10 deg rot angle\n",
    "    1.05 scale factor\n",
    "    31 min_neighbor values\n",
    "        7 out of 10\n",
    "\n",
    "    20 deg rot angle\n",
    "    1.01 scale factor\n",
    "    31 min_neighbor values\n",
    "       8 out of 10!\n",
    "\n",
    "    20 deg rot angle\n",
    "    1.01 scale factor\n",
    "    51 min_neighbor values\n",
    "        7 out of 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score of new cascades\n",
    "image size: 40, 60, 80\n",
    "hit rates: 0.99, 0.995, 0.999\n",
    "stages: 25, 30\n",
    "\n",
    "40_25_0.99:  84%\n",
    "40_25_0.995: 88%\n",
    "40_25_0.999: 86%\n",
    "\n",
    "40_30_0.999: 90%\n",
    "\n",
    "60_25_0.99:  85%\n",
    "60_25_0.999: 89%\n",
    "60_25_0.995: 87%\n",
    "\n",
    "80_25_0.995: 87%\n",
    "80_25_0.999: 86%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find face in all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  images done.\n",
      "w_6414\n",
      "w_5536\n",
      "w_3635\n",
      "w_7704\n",
      "w_7443\n",
      "w_266\n",
      "w_4919\n",
      "w_614\n",
      "w_1124\n",
      "w_2379\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.ndimage.interpolation import rotate\n",
    "import glob\n",
    "from scipy.misc import imresize\n",
    "import csv\n",
    "from collections import Counter\n",
    "\n",
    "def read_data_csv(name):\n",
    "   \"\"\"\n",
    "   read cvs file and return contents\n",
    "   \"\"\"\n",
    "\n",
    "   file_name = []\n",
    "   whale_ID = []\n",
    "   \n",
    "   with open(name, 'rb') as f:\n",
    "      reader = csv.reader(f)\n",
    "\n",
    "      # skip header\n",
    "      reader.next()\n",
    "\n",
    "      for row in reader:  \n",
    "         file_name.append(row[0][:-4])\n",
    "         whale_ID.append(row[1])\n",
    "           \n",
    "   file_name = np.array(file_name)\n",
    "   whale_ID = np.array(whale_ID)\n",
    "   \n",
    "   return file_name,whale_ID\n",
    "        \n",
    "# mean and std of images, based on previous code\n",
    "mean = 111.031397463 \n",
    "std = 18.489856209\n",
    "\n",
    "# cascade parameters\n",
    "Im_size = 60\n",
    "NumCascadeStages = 30\n",
    "MinHitRate = 0.995\n",
    "\n",
    "scalefac = 1.01\n",
    "min_neighbors = np.arange(1,10,step = 1)\n",
    "min_neighbors = np.append(min_neighbors,10e0**np.linspace(1e0,4e0,11e0))\n",
    "min_neighbors = min_neighbors.astype(int)\n",
    "rot = np.linspace(0,350,36)\n",
    "\n",
    "# collecing the image file names\n",
    "#files = []\n",
    "#for file in os.listdir(\"../imgs/\"):\n",
    "#    if file.endswith('.jpg'):\n",
    "#        files.append(file[:-4])\n",
    "\n",
    "# collecting the labelled images\n",
    "files,ID = read_data_csv('../train.csv')\n",
    "\n",
    "# number of images to map \n",
    "n = 500\n",
    "if n > len(files):\n",
    "    n = len(files)\n",
    "\n",
    "for ii in range(n):\n",
    "    # check which images had been analyzed already\n",
    "    whale_faces = []\n",
    "    for file in os.listdir(\"../whale_faces/\"):\n",
    "        if file.endswith('.jpg'):\n",
    "            whale_faces.append(file[:-4])\n",
    "\n",
    "    # select a new file\n",
    "    f = np.random.choice(list(set(files) - set(whale_faces)))\n",
    "    \n",
    "    if ii%10 == 0:\n",
    "        print ii,' images done.'\n",
    "\n",
    "    # open image\n",
    "    im = np.array(Image.open('../imgs/'+f+'.jpg'))\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # standardize and restandardize based on the average mean and std\n",
    "    gray = (gray - np.mean(gray)) / np.std(gray)\n",
    "    gray = (gray*std)+mean\n",
    "    gray[gray < 0e0] = 0e0\n",
    "    gray[gray > 255e0] = 255e0\n",
    "    gray_ori = np.array(gray, dtype='uint8')\n",
    "    \n",
    "    # loop through rotation angles\n",
    "    print f    \n",
    "    max_min_neighbors_old = 0\n",
    "    for jj in np.arange(len(rot)):\n",
    "        # rotate image\n",
    "        gray = rotate(gray_ori,rot[jj])        \n",
    "        \n",
    "        # load the cascade\n",
    "        face_cascade = cv2.CascadeClassifier('../haar_train_1step/cascade_'+str(Im_size)+'_'+str(NumCascadeStages)+'_'+str(MinHitRate)+'_normalized_straight/cascade.xml')\n",
    "\n",
    "        # increase min_neighbors and count how many times one face is found on the image \n",
    "        # (if min_neighbors is small, multiple rectangles are marked.)\n",
    "        # if 0 face is found, end the while loop\n",
    "        # save the face with the highest found value\n",
    "        a = np.min(np.shape(gray_ori))        \n",
    "        faces_all = []\n",
    "        max_min_neighbors = 0\n",
    "        l = 0\n",
    "        nr_faces = 1\n",
    "        while (nr_faces > 0) and (l < len(min_neighbors)):\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=scalefac, minNeighbors = min_neighbors[l], minSize=(a/30, a/30))\n",
    "            nr_faces = np.shape(faces)[0]\n",
    "            if nr_faces == 1:\n",
    "                max_min_neighbors = min_neighbors[l]\n",
    "                faces_all.append(faces)\n",
    "            l = l + 1\n",
    "        # save the face if its found value is higher than any previous encountered value\n",
    "        print jj,max_min_neighbors\n",
    "        if max_min_neighbors > max_min_neighbors_old:\n",
    "            face_cut = faces_all[-1]\n",
    "            #gray_copy = np.copy(gray)\n",
    "            im_rot = rotate(im,rot[jj])\n",
    "            for (x,y,w,h) in face_cut:\n",
    "                #cv2.rectangle(gray_copy,(x,y),(x+w,y+h),(255,255,255),10)\n",
    "                #imsave('../haar_train_1step/test3/'+f+'_'+str(jj)+'.jpg', imresize(gray_copy,[np.shape(gray)[0]/4,np.shape(gray)[1]/4]))\n",
    "                imsave('../whale_faces/'+f+'.jpg', im_rot[y:y+h,x:x+w])\n",
    "        max_min_neighbors_old = np.max([max_min_neighbors,max_min_neighbors_old])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
