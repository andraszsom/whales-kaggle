{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2015, Brown University, Providence, RI.\n",
    "\n",
    "                        All Rights Reserved\n",
    "\n",
    "Permission to use, copy, modify, and distribute this software and its\n",
    "documentation for any purpose other than its incorporation into a\n",
    "commercial product is hereby granted without fee, provided that the\n",
    "above copyright notice appear in all copies and that both that\n",
    "copyright notice and this permission notice appear in supporting\n",
    "documentation, and that the name of Brown University not be used in\n",
    "advertising or publicity pertaining to distribution of the software\n",
    "without specific, written prior permission.\n",
    "\n",
    "BROWN UNIVERSITY DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE,\n",
    "INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR ANY\n",
    "PARTICULAR PURPOSE.  IN NO EVENT SHALL BROWN UNIVERSITY BE LIABLE FOR\n",
    "ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES\n",
    "WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN\n",
    "ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF\n",
    "OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading images\n",
      "doing PCA\n",
      "(6400, 4544)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:96: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:102: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:70: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(4544, 160, 40)\n",
      "70.02 % variance retained in 19 dimensions\n",
      "75.28 % variance retained in 31 dimensions\n",
      "80.10 % variance retained in 50 dimensions\n",
      "85.07 % variance retained in 85 dimensions\n",
      "90.00 % variance retained in 157 dimensions\n",
      "95.01 % variance retained in 357 dimensions\n",
      "99.00 % variance retained in 1115 dimensions\n",
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:73: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# perform PCA on all labeled images\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy.misc import imsave\n",
    "from scipy.misc import imresize\n",
    "from PIL import Image\n",
    "from scipy.stats import chisquare\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "# size of the long side of the image (usually 10% edge is cut out)\n",
    "# for feature detection, img_size = 400 is recommended\n",
    "img_size = 200\n",
    "var_ret = [0.70,0.75,0.80,0.85,0.90,0.95,0.99]\n",
    "filename = '../PCA_whale_faces/PCA_face_'+str(img_size)+'x'+str(img_size/2)+'_all_var0'\n",
    "\n",
    "mean = 111.031397463 \n",
    "std = 18.4898562094\n",
    "\n",
    "def read_data_csv(name):\n",
    "   \"\"\"\n",
    "   read cvs file and return contents\n",
    "   \"\"\"\n",
    "\n",
    "   file_name = []\n",
    "   whale_ID = []\n",
    "   \n",
    "   with open(name, 'rb') as f:\n",
    "      reader = csv.reader(f)\n",
    "\n",
    "      # skip header\n",
    "      reader.next()\n",
    "\n",
    "      for row in reader:  \n",
    "         file_name.append(row[0])\n",
    "         whale_ID.append(row[1])\n",
    "           \n",
    "   file_name = np.array(file_name)\n",
    "   whale_ID = np.array(whale_ID)\n",
    "   \n",
    "   return file_name,whale_ID\n",
    "\n",
    "\n",
    "def PCA(X, varRetained = [0.95],filename = 'PCA_data.dat',label = [], files = []):\n",
    "    '''\n",
    "    Performs the Principal Coponent analysis of the Matrix X\n",
    "    Matrix must be n * m dimensions\n",
    "    where n is # features\n",
    "    m is # examples\n",
    "    '''\n",
    "    # Compute Covariance Matrix Sigma\n",
    "    (n, m) = X.shape\n",
    "\n",
    "    Sigma = 1.0 / float(m) * np.dot(X, np.transpose(X))\n",
    "    # Compute eigenvectors and eigenvalues of Sigma\n",
    "    U, s, V = np.linalg.svd(Sigma)\n",
    "\n",
    "    # compute the value k: number of minumum features that \n",
    "    # retains the given variance\n",
    "    s_tot = np.sum(s)\n",
    "        \n",
    "    var_i = np.array([np.sum(s[: i + 1]) / s_tot * 100.0 for i in range(n)])\n",
    "    \n",
    "    k = np.zeros(len(varRetained))\n",
    "    for i in range(len(k)):\n",
    "        k[i] = len(var_i[var_i < (varRetained[i] * 100e0)])\n",
    "\n",
    "        print '%.2f %% variance retained in %d dimensions' % (var_i[k[i]], k[i])\n",
    "\n",
    "        # compute the reduced dimensional features \n",
    "        U_reduced = U[:, : k[i]]\n",
    "        Z = np.dot(np.transpose(U_reduced),X)\n",
    "\n",
    "        # pickle dump the results\n",
    "        f = open(filename+str(int(varRetained[i]*100e0))+'.dat','w')\n",
    "        pickle.dump([Z, U_reduced, k[i],label, files],f)\n",
    "        f.close() \n",
    "\n",
    "    return \n",
    "\n",
    "\n",
    "name,ID = read_data_csv('../train.csv')\n",
    "\n",
    "faces = np.unique(ID)\n",
    "\n",
    "# find files in these directories\n",
    "files = []\n",
    "\n",
    "for i in range(len(faces)):\n",
    "    for file in os.listdir(\"../PCA_whale_faces/\"+faces[i]):\n",
    "        if file.endswith('.jpg'):\n",
    "            files.append(faces[i]+'/'+file)\n",
    "\n",
    "imgs = np.zeros([len(files),img_size*0.8,(img_size/2e0 - img_size*0.3)])\n",
    "IDs = np.zeros([len(files)])\n",
    "\n",
    "\n",
    "print 'loading images'\n",
    "\n",
    "for j in range(len(files)):\n",
    "    img = imresize(np.array(Image.open('../whale_faces/'+files[j][12:]).convert('L')),[img_size,img_size/2])[img_size/10:-img_size/10,img_size*0.15:-img_size*0.15]\n",
    "    # standardize image\n",
    "    img = (img - np.mean(img)) / np.std(img)\n",
    "    # restandardize image\n",
    "    img = (img*std*3e0)+mean\n",
    "    img[img < 0e0] = 0e0\n",
    "    img[img > 255e0] = 255e0\n",
    "    img = np.array(img, dtype='uint8')    \n",
    "\n",
    "    #if j%2 == 0:\n",
    "    #    # flip the image\n",
    "    #    imgs[j,:] = np.fliplr(img)\n",
    "    #else:\n",
    "    imgs[j,:] = img\n",
    "    \n",
    "    for i in range(len(faces)):\n",
    "        if files[j][:11] == faces[i]:\n",
    "            IDs[j] = faces[i][6:]\n",
    "\n",
    "            \n",
    "print 'doing PCA'\n",
    "\n",
    "# standardize the images\n",
    "imgs_standard = np.zeros(np.shape(imgs))\n",
    "mean = np.mean(imgs,axis=(1,2))\n",
    "std = np.std(imgs,axis=(1,2))\n",
    "for i in range(len(files)):\n",
    "    imgs_standard[i,:,:] = (imgs[i,:,:] - mean[i] ) / std[i] \n",
    "\n",
    "imgs_l = np.reshape(imgs_standard,[len(files),np.prod(np.shape(imgs[0,:,:]))])\n",
    "imgs_learn = np.transpose(imgs_l)\n",
    "\n",
    "print np.shape(imgs_learn)\n",
    "print np.shape(imgs)\n",
    "\n",
    "# do PCA and save the results\n",
    "PCA(imgs_learn,varRetained = var_ret,filename = filename,label = IDs, files = files)\n",
    "\n",
    "print 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading PCA data and training nearest neighbors\n",
      "reading images"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:39: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:43: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run kneighbors\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "# generate a submission file using imgs from whale_faces, PCA with nearest neighbor approach\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy.misc import imsave\n",
    "import glob\n",
    "import csv\n",
    "from scipy.misc import imresize\n",
    "from PIL import Image\n",
    "\n",
    "img_size = 300\n",
    "\n",
    "print 'loading PCA data and training nearest neighbors'\n",
    "\n",
    "f = open('../PCA_whale_faces/PCA_face_'+str(img_size)+'x'+str(img_size/2)+'_all_var090.dat','r')\n",
    "[Z, U_reduced, k, label, files] = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "X_train = np.transpose(Z)\n",
    "Y_train = label\n",
    "whale_IDs, ID_counts = np.unique(label,return_counts=True)\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=10).fit(X_train)\n",
    "\n",
    "print 'reading images'\n",
    "\n",
    "files_test = []\n",
    "with open('../sample_submission.csv', 'rb') as f:\n",
    "    reader = csv.reader(f)\n",
    "\n",
    "    # skip header\n",
    "    header = reader.next()\n",
    "    \n",
    "    for row in reader:  \n",
    "        files_test.append(row[0])\n",
    "    \n",
    "# read images\n",
    "imgs = np.zeros([len(files_test),img_size*0.8,(img_size/2e0 - img_size*0.3)])\n",
    "mean = np.zeros(len(files_test))\n",
    "std = np.zeros(len(files_test))\n",
    "for j in range(len(files_test)):\n",
    "    img = imresize(np.array(Image.open('../whale_faces/'+files_test[j]).convert('L')),[img_size,img_size/2])[img_size/10:-img_size/10,img_size*0.15:-img_size*0.15]\n",
    "    # standardize image\n",
    "    mean[j] = np.mean(img)\n",
    "    std[j] = np.std(img)\n",
    "    img = (img - mean[j]) / std[j]\n",
    "    imgs[j,:] = img\n",
    "    \n",
    "# reshape array\n",
    "imgs_r = np.reshape(imgs,[len(files_test),np.prod(np.shape(imgs[0,:,:]))])\n",
    "# project imgs_r to U_reduced\n",
    "X_test = np.transpose(np.dot(np.transpose(U_reduced),np.transpose(imgs_r)))\n",
    "\n",
    "print 'run kneighbors'\n",
    "distances, indcs = nbrs.kneighbors(X_test)\n",
    "print 'finished'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create submission file\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-138f507ea6f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mwhale_IDs_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mID_counts_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-138f507ea6f5>\u001b[0m in \u001b[0;36mread_data_csv\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# skip header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'csv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'create submission file'\n",
    "\n",
    "def read_data_csv(name):\n",
    "   \"\"\"\n",
    "   read cvs file and return contents\n",
    "   \"\"\"\n",
    "\n",
    "   file_name = []\n",
    "   whale_ID = []\n",
    "   \n",
    "   with open(name, 'rb') as f:\n",
    "      reader = csv.reader(f)\n",
    "\n",
    "      # skip header\n",
    "      reader.next()\n",
    "\n",
    "      for row in reader:  \n",
    "         file_name.append(row[0])\n",
    "         whale_ID.append(int(row[1][-5:]))\n",
    "           \n",
    "   file_name = np.array(file_name)\n",
    "   whale_ID = np.array(whale_ID)\n",
    "   \n",
    "   return file_name,whale_ID\n",
    "\n",
    "\n",
    "name,ID = read_data_csv('../train.csv')\n",
    "whale_IDs_all, ID_counts_all = np.unique(ID,return_counts=True)\n",
    "\n",
    "\n",
    "# scaling constants to try\n",
    "const1 = np.max(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0])\n",
    "const2 = np.max(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0]**2e0)\n",
    "const3 = np.max(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0]**3e0)\n",
    "const4 = np.max(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0]**4e0)\n",
    "const5 = np.max(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0]**5e0)\n",
    "\n",
    "const32 = np.min(1e0*ID_counts/float(len(whale_IDs))) / np.min(1e0/distances[:,0]**3e0)\n",
    "\n",
    "\n",
    "with open('../submissions/submission_newcascade_leancut_sorted_300_varret90_c4\\d4_nonuni.csv', 'wb') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(header)\n",
    "    # loop through the images\n",
    "    for i in range(len(files_test)):\n",
    "        # generate scores for the image\n",
    "        scores = np.zeros(len(whale_IDs_all))\n",
    "\n",
    "        # loop through the whale IDs\n",
    "        for j in range(len(whale_IDs_all)):\n",
    "            scores[j] = float(ID_counts_all[j])/float(len(whale_IDs_all))\n",
    "        \n",
    "        for j in range(len(whale_IDs_all)):\n",
    "            \n",
    "            if Y_train[indcs[i,0]] == whale_IDs_all[j]:\n",
    "                scores[j] = 4e0*const4/(distances[i,0]**4e0)\n",
    "            #if Y_train[indcs[i,1]] == whale_IDs[j]:\n",
    "            #    scores[j] = 1\n",
    "            #if Y_train[indcs[i,2]] == whale_IDs[j]:\n",
    "            #    scores[j] = 1\n",
    "        writer.writerow([files_test[i]]+list(scores))\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
